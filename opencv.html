<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1"/>
        <link rel="stylesheet" href="/style.css" type="text/css"/>
        <title>Seeing Danger: How AI-Based Computer Vision Detects Firearms to Boost Security</title>
        <style>
            video {
                max-width: 100%;
                height: auto;
                display: block;
                margin: 0 auto;
            }
        </style>
    </head>
    <body>
        <header class='header'>
            <a class="logo" href="index.html">home</a>
            <nav>
                <a href="https://www.github.com/ZeshanHussain">github</a>
                <a href="/about.html">about</a>
                <a href="/resume.html" class="active">resume</a>
            </nav>
        </header>
        <div class="container">
            <h1 class="title">
                Seeing Danger: How AI-Based Computer Vision Detects Firearms to Boost Security
        <br>
                <span class="subtitle"></span>
            </h1>
            <ul class="tags">
                <li>
                    <a href="/tags/c++">c++</a>
                </li>
                <li>
                    <a href="/tags/opencv">opencv</a>
                </li>
            </ul>
            <p>
                This is not just a project; it's the foundation of a startup I'm building to revolutionize security solutions. The goal is to create an advanced AI-powered surveillance system capable of identifying and responding to potential threats in real-time. Using the <a href="https://github.com/AlexeyAB/darknet" target="_blank">YOLO/Darknet framework</a>, I built and trained a specialized neural network designed to detect active shooter scenarios with exceptional precision. By leveraging a convolutional neural network (CNN), this project is designed to enhance safety and reliability in real-world security applications.               <sup class="footnote-reference">
                    <a id="footnote-reference-1" href="#footnote-1">1</a>
                </sup>
                
            </p>
            <hr>
            <h3 style="text-decoration: underline;">Technologies Used</h3>
            <ul>
                <li>YOLO/Darknet: High-performance convolutional neural network framework. </li>
                <li> DarkMark: Annotation and training tool for fine-tuning models. </li>
                <li> FlTK: Used FLTM framework to write C++-based GUI I engineered for minimal memory consumption. </li>
                <li> C++: Core programming language for the system's backend. </li> 
                <li> HTML: For explaining my goal for this startup/project. </li>
                <li> Twilio Voice API: Facilitates instant voice alerts for critical situations. </li>
            </ul>
            <hr>
            
            <div style="margin: 2.5em 0; padding: 1.5em; background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); border-radius: 12px; box-shadow: 0 8px 24px rgba(0,0,0,0.15);">
                <h3 style="color: white; margin: 0 0 1em 0; text-align: center; font-size: 1.3em;">AI Detection in Action</h3>
                <div style="position: relative; width: 100%; max-width: 900px; margin: 0 auto 2em auto; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 12px rgba(0,0,0,0.3);">
                    <video width="100%" height="auto" playsinline autoplay loop muted controls style="display: block; border-radius: 8px;">
                        <source src="Hussain_Zeshan_Example.mp4" type="video/mp4" />
                        Your browser does not support the video tag.
                    </video>
                </div>
                <p style="color: rgba(255,255,255,0.9); text-align: center; margin: 0 0 1.5em 0; font-size: 0.9em; font-style: italic;">
                    Real-time firearm detection with 99% accuracy
                </p>
                
                <div style="position: relative; width: 100%; max-width: 900px; margin: 0 auto; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 12px rgba(0,0,0,0.3);">
                    <video width="100%" height="auto" playsinline autoplay loop muted controls style="display: block; border-radius: 8px;">
                        <source src="Neural (1).mp4" type="video/mp4" />
                        Your browser does not support the video tag.
                    </video>
                </div>
                <p style="color: rgba(255,255,255,0.9); text-align: center; margin: 1em 0 0 0; font-size: 0.9em; font-style: italic;">
                    Neural network training and validation results
                </p>
            </div>
            <p>How it works:</p>
            <ol>
                <li>Trained millions of Postive and Negative Datasets for Machine learning task</li>
                <li>After Training, deploy the model weights into the C++ program</li>
                <li>My C++ program consists of using the OpenCV framework. Using this framework helped me create a clear goal for object detection.</li>
                
            </ol>
            <p>And yup, that works. But not without jumping through a few hoops:</p>
            <ul>
                <li>
                    We can use this basic technology to save many lives. During active threat situations on school grounds, the attacker often comes from an entry point around the school, which can catch staff, teachers, and students off guard. Having a detection system can cut response time in half and save many lives. In situations like this, every second really matters. 
                    <div class="src src-bash">
                        <div class="highlight">
                            <pre style="background-color:#fff;">
                                <code>
                                    <span style="display:flex;">
                                        
  <span style="color:#4300ec">#include</span> <span style="color:#48a8e4"> opencv2/opencv.hpp </span> </span><span style="color:#4300ec">#include</span> <span style="color:#48a8e4">opencv2/highgui/highgui.hpp </span>
<span style="color:#4300ec">#include</span> <span style="color:#48a8e4">opencv2/imgproc/imgproc.hpp </span></span>
<span style="color:#4300ec">#include</span> <span style="color:#48a8e4">iostream </span></span>
<span style="color:#4300ec">#include</span> <span style="color:#48a8e4">opencv2/objdetect/objdetect.hpp </span>   </span>

<span style="color:#ee8300">using namespace std; </span>
<span style="color:#ee8300">using namespace cv;</span>

<span style="color:#711eb5"> 
#include "FL/Fl.H"
#include "FL/Fl_Window.H"
#include "darknet.hpp"
#include "darknet_cfg_and_state.hpp"
#include "FL/Fl_Box.H"
#include "FL/Fl_Button.H"
#include "FL/Fl_Toggle_Button.H"
#include "opencv2/opencv.hpp"
#include "iostream"
#include "thread"
#include "chrono"
#include "iomanip"
<span style="color:#ee8300">
    class WebcamWindow : public Fl_Window {
        private:
            Fl_Box* videoBox; // Pointer to a box widget to display the video feed
            cv::VideoCapture cap; // OpenCV object to capture video from the desired camera  
            cv::Mat frame, resizedFrame; // Matrices to hold the current frame and the resized version of it for display
            Fl_RGB_Image* img; // Pointer to an image object to hold the current frame for display the video frame in rhe GUI 
            bool stopFlag; // Video Capture Flag
            cv::VideoWriter videoWriter; 
            bool isRecording; 
            std::string currentVideoFile;
        
            std::string getTimestamp()
            {
                auto now = std::chrono::system_clock::now();
                auto in_time_t = std::chrono::system_clock::to_time_t(now);
                std::stringstream ss; 
                ss << std::put_time(std::localtime(&in_time_t), "%Y%m%d_%H%M%S");
                return ss.str();
            }
        void startRecording() {
                currentVideoFile = "recording_" + getTimestamp() + ".avi";
                int fourcc = cv::VideoWriter::fourcc('M','J','P','G'); // Motion-JPEG codec
                double fps = estimated_fps;
                cv::Size frameSize(cap.get(cv::CAP_PROP_FRAME_WIDTH), 
                                  cap.get(cv::CAP_PROP_FRAME_HEIGHT));
                // button camera works
                if(videoWriter.open(currentVideoFile, fourcc, fps, frameSize)) {
                    isRecording = true;
                    recordButton->label("Stop");
                    recordButton->color(fl_rgb_color(255, 0, 0)); // Red when recording
                    std::cout << "Recording started: " << currentVideoFile << std::endl;
                } else {
                    std::cerr << "Failed to initialize video writer!" << std::endl;
                }
            }
        
            void stopRecording()
             {
                isRecording = false; 
                videoWriter.release(); 
                recordButton->label("Record");
                recordButton->color(fl_rgb_color(34, 139, 34)); // Original green color
                std::cout << "Recording saved: " << currentVideoFile << std::endl;
        
             }
             static void record_button_callback(Fl_Widget* widget, void* data)
             {
                WebcamWindow* win = static_cast<WebcamWindow*>(data);
                if(!win->isRecording)
                {
                    win->startRecording();
                } else {
                    win->stopRecording();
                }
             }
        
        
            // Neural network
            Darknet::NetworkPtr net; // Pointer to the neural network object detection 
        
            // FPS and statistics
            double estimated_fps;
            size_t frame_counter;
            size_t total_objects_found;
            std::chrono::high_resolution_clock::time_point timestamp_start;
        
            // Top bar widgets
            Fl_Box* topBar; // Pointer to the top bar widget
            Fl_Button* exitButton; // Pointer to the exit button widget
        
            // Create the action button
            Fl_Button* actionButton;
            Fl_Button* alertButton; 
            Fl_Button* settingsButton;
            Fl_Button* recordButton;
            Fl_Button* CameralistButton;
            Fl_Button* viewButton;
            // Strings for GuardiansafeAI Neural Network Model paths(cfg, names, weights)
            const std::string MODEL_CFG = "/home/zeshan/src/darknet/src-examples/Shooter.cfg";
            const std::string MODEL_NAMES = "/home/zeshan/src/darknet/src-examples/Shooter.names";
            const std::string MODEL_WEIGHTS = "/home/zeshan/src/darknet/src-examples/Shooter_best.weights";
        
<span style="color:#48a8e4">
    double estimate_camera_fps(cv::VideoCapture & cap) {
        std::cout << "Estimating FPS..." << std::endl;

        // Read and discard a few frames to allow the camera to stabilize
        cv::Mat mat;
        for (int i = 0; i < 5; i++) {
            cap >> mat;
        }

        // Estimate FPS by reading several consecutive frames
        size_t frame_counter = 0;
        const auto ts1 = std::chrono::high_resolution_clock::now();
        for (int i = 0; cap.isOpened() and i < 5; i++) {
            cap >> mat;
            if (!mat.empty()) {
                frame_counter++;
            }
        }
        const auto ts2 = std::chrono::high_resolution_clock::now();

        const double actual_fps = static_cast<double>(frame_counter) / std::chrono::duration_cast<std::chrono::nanoseconds>(ts2 - ts1).count() * 1000000000.0;
        return actual_fps;
    }

    void drawAppleStyleText(cv::Mat& frame, const std::string& text, cv::Point position, double fontScale, int thickness) {
        // Calculate the size of the text
        int baseline = 0;
        cv::Size textSize = cv::getTextSize(text, cv::FONT_HERSHEY_SIMPLEX, fontScale, thickness, &baseline);

        // Define the background rectangle for the text
        cv::Rect bgRect(
            position.x, // X-coordinate of the top-left corner
            position.y - textSize.height, // Y-coordinate of the top-left corner
            textSize.width, // Width of the rectangle
            textSize.height + baseline // Height of the rectangle
        );

        // Create a semi-transparent black background for the text
        cv::Mat overlay = frame.clone();
        cv::rectangle(overlay, bgRect, cv::Scalar(0, 0, 0), cv::FILLED); // Black rectangle
        cv::addWeighted(overlay, 0.3, frame, 0.7, 0, frame); // Blend with the original frame (30% opacity)

        // Draw the text with a subtle shadow
        cv::putText(frame, text, position + cv::Point(2, 2), cv::FONT_HERSHEY_SIMPLEX, fontScale, cv::Scalar(0, 0, 0), thickness); // Shadow
        cv::putText(frame, text, position, cv::FONT_HERSHEY_SIMPLEX, fontScale, cv::Scalar(255, 120, 255), thickness); // Main text
    }

    void updateFrame() {
        if (!cap.read(frame)) {
            std::cerr << "Error: Failed to capture frame!" << std::endl;
            return;
        }

        // Process the frame through the neural network
        const auto results = Darknet::predict_and_annotate(net, frame);
        total_objects_found += results.size();

        // Calculate FPS
        const auto now = std::chrono::high_resolution_clock::now();
        const double elapsed_seconds = std::chrono::duration_cast<std::chrono::nanoseconds>(now - timestamp_start).count() / 1000000000.0;
        const double current_fps = frame_counter / elapsed_seconds;

        // Prepare multi-line text
        std::stringstream stats;
        stats << "FPS: " << std::fixed << std::setprecision(1) << current_fps << "\n"
              << "Objects: " << total_objects_found << "\n"
              << "Frame: " << frame_counter;

        // Split the text into lines
        std::vector<std::string> lines;
        std::string line;
        while (std::getline(stats, line, '\n')) {
            lines.push_back(line);
        }

        // Render each line with Apple-style text
        int y_offset = 30; // Starting Y position for the first line
        for (const auto& text_line : lines) {
            drawAppleStyleText(frame, text_line, cv::Point(10, y_offset), 0.7, 2);
            y_offset += 30; // Increment Y position for the next line
        }

        // Convert the frame to RGB for display
        cv::cvtColor(frame, frame, cv::COLOR_BGR2RGB);
        cv::resize(frame, resizedFrame, resizedFrame.size());

        if (img) {
            delete img;
        }
        img = new Fl_RGB_Image(resizedFrame.data, resizedFrame.cols, resizedFrame.rows, 3);

        videoBox->image(img);
        videoBox->redraw();

        frame_counter++;
    }

    static void captureLoop(void* userdata) {
        WebcamWindow* win = static_cast<WebcamWindow*>(userdata);
        while (!win->stopFlag) {
            win->updateFrame();
            Fl::check();
            std::this_thread::sleep_for(std::chrono::milliseconds(1000 / 30)); // Aim for 30 FPS
        }
    }

    void startCapture() {
        std::thread captureThread(captureLoop, this);
        captureThread.detach();
    }

    ~WebcamWindow() {
        stopFlag = true;
        if (img) {
            delete img;
        }
        cap.release();
        Darknet::free_neural_network(net);
    }
};

int main(int argc, char* argv[]) {
    WebcamWindow window(640, 480, "FLTK Webcam", argc, argv);
    window.show();
    window.startCapture();
    return Fl::run();
}

</span>




                                    

                                    <span style="display:flex;">
                                        <span>
                                           
                                        </span>
                                    </span>
                                    <span style="display:flex;">
                                        <span>
  
                                        </span>
                                    </span>
                                    <span style="display:flex;">
                                        <span>
                                            
                                        </span>
                                    </span>
                                </code>
                            </pre>
                        </div>
                    </div>
                    <p>
                  
            <p>For now it works well enough - lets build :D</p>
            <div id="outline-container-headline-1" class="outline-2">
                <h2 id="headline-1">Footnotes
</h2>
            </div>
            <div class="footnotes">
                <hr class="footnotes-separatator">
                <div class="footnote-definitions">
                    <div class="footnote-definition">
        
                    <div class="footnote-definition">
                        <sup id="footnote-2">
                            <a href="#footnote-reference-2">2</a>
                        </sup>
                        <div class="footnote-body">
                            <p>
                                For more info, check e.g. <a href="https://docs.opencv.org/4.x/de/d37/group__objdetect__cascade__classifier.html">OpenCv Documentation</a>
                                
                            </p>
                        </div>
                    </div>
                    <div class="footnote-definition">
                        <sup id="footnote-3">
                            <a href="#footnote-reference-3">3</a>
                        </sup>
                        <div class="footnote-body">
                            <p>
                                <a href="https://unix.stackexchange.com/questions/366797/grep-slow-to-exit-after-finding-match">https://unix.stackexchange.com/questions/366797/grep-slow-to-exit-after-finding-match</a>
                                - so that &#39;s why pipes sometimes seem to get &#34;stuck &#34;- never thought about how things work. TIL.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    <!-- Code injected by live-server -->
<script type="text/javascript">
	// <![CDATA[  <-- For SVG support
	if ('WebSocket' in window) {
		(function() {
			function refreshCSS() {
				var sheets = [].slice.call(document.getElementsByTagName("link"));
				var head = document.getElementsByTagName("head")[0];
				for (var i = 0; i < sheets.length; ++i) {
					var elem = sheets[i];
					head.removeChild(elem);
					var rel = elem.rel;
					if (elem.href && typeof rel != "string" || rel.length == 0 || rel.toLowerCase() == "stylesheet") {
						var url = elem.href.replace(/(&|\?)_cacheOverride=\d+/, '');
						elem.href = url + (url.indexOf('?') >= 0 ? '&' : '?') + '_cacheOverride=' + (new Date().valueOf());
					}
					head.appendChild(elem);
				}
			}
			var protocol = window.location.protocol === 'http:' ? 'ws://' : 'wss://';
			var address = protocol + window.location.host + window.location.pathname + '/ws';
			var socket = new WebSocket(address);
			socket.onmessage = function(msg) {
				if (msg.data == 'reload') window.location.reload();
				else if (msg.data == 'refreshcss') refreshCSS();
			};
			console.log('Live reload enabled.');
		})();
	}
	// ]]>
</script>
</body>
</html>

